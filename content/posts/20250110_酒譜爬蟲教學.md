+++
title = "cocktail webcrawler"
date = 2025-01-10T13:30:00+08:00
draft =  false
tags = ["web crawler", "cocktail", "ingredients", "Learning record"]
categories = ["Learning"]

[cover]
    image =  "webcrawler.jpg"
    alt = '20250110'
    caption = 'webcrawler.jpg by JackHuang'
+++

**這是給我自己的一份教學，以免日子久了忘記怎麼爬蟲，同時也是一篇學習紀錄**  
**擁有一個可以寫code的環境，網路上很多安裝環境的教學**  
**我是用anoconda的vs code寫code的**
```
import requests as req
# 向客戶端要求網址  
from bs4 import BeautifulSoup as B
# 索取網址內容  
import pandas as pd
# 最後將結果輸出為CSV檔
import time
# 避免爬蟲時被抓到是爬蟲，所以移用這個延長每次爬蟲時間，假裝自己是人類
import random
# 延遲隨機時間用的
builder_url = 'https://www.theeducatedbarfly.com/cocktail-builder/'
# 我是用 **cocktail builder** 這個網站來爬蟲我要的酒單  
header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36'}
# 起初在爬的時候有發現跑不出資料，所以新增header來假裝我是人類，網路上也有很多如何在瀏覽器找header的教學
resp = req.get(builder_url, headers=header)
# 建立抓取url的回應變數
cocktail_name_list = []
# 建立空清單，將抓取到的資料先放進來，以便最後做成dataframe
if resp.status_code == 200:
# 確定你的url是可以連線的
    soup = B(resp.text, 'html.parser')
    # 建立爬蟲的頭頭，後面的html.parser是每次建立都要有，好像是用來解析html的功能
    for cocktail_name in soup.find_all('div', class_="wpupg-item-title wpupg-block-text-bold"):
    # 打開網頁按下F2，按下ctrl+shift+c進入選取網頁元素模式，點選任一調酒，會指引到該調酒的block
    # 你會發現所有的調酒名稱都在'div', class_="wpupg-item-title wpupg-block-text-bold"這個標籤底下，所以我們利用find_all遍歷該標籤
        name = cocktail_name.text.strip()
        # 調酒名稱都在'div', class_="wpupg-item-title wpupg-block-text-bold"的標籤的text內容中，strip()是去掉text前後多餘的空格
        if name:
        # 確定該標籤有內容才抓，沒有就不抓
            cocktail_name_list.append(name)
            # 抓到修飾後的text並放入剛剛建立的list
    time.sleep(random.uniform(1,3))
    # 每次抓完一個就等待 1~3 秒

cocktail_name_df = pd.DataFrame(cocktail_name_list, columns=['Name'])
# 將抓完後的清list建立成一個Dataframe，以Name當作該欄位的名稱

cocktail_data = []
# 這是最後的調酒名稱+該調酒的材料的空清單

for name in cocktail_name_df['Name']:
    urls = f'https://www.theeducatedbarfly.com/{name.replace(" ", "-").lower()}/'
    # 建立每個調酒的url，點進去隨便一個調酒，你會發現網址是https://www.theeducatedbarfly.com/xxx-xxx/
    # xxx是該調酒的名稱，只是我們剛剛的調酒名稱list有大寫而且中間是空格不是-，所以用replace將空格替換成-，且轉為小寫
    resp = req.get(urls, headers=header)
    if resp.status_code == 200:
        soup = B(resp.text, 'html.parser')
        # 查找所有具有指定 class 的 <span> 元素
        ingredients = soup.find_all('span', class_='wprm-recipe-ingredient-name')
        ingredient_name_list = []
        for ingredient in ingredients:
        # 提取<a>標籤的文字內容
            ingredient_name = ingredient.find('a')
            if ingredient_name:  
            # 確保<a>存在
                ingredient_name_list.append(ingredient_name.text.strip())

        cocktail_data.append({'Cocktail Name': name, 'Ingredients': ", ".join(ingredient_name_list)})
        # 最後就是將剛剛抓到的Name跟這個Inredients清單中每個素材加入剛剛建立的加入剛剛建立的cocktail_data清單中
    time.sleep(random.uniform(1,3))

cocktail_df = pd.DataFrame(cocktail_data)
# 最後的最後將list轉為Dataframe並用pd.to_csv輸出成csv檔，結束這回合
```
**以上是我提醒自己的爬蟲教學**  
**有任何疑問歡迎提出**  
~雖然我還沒有建立留言板就是了~


