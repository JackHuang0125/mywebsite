<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Learning on Yang&#39;s World</title>
    <link>http://localhost:1313/categories/learning/</link>
    <description>Recent content in Learning on Yang&#39;s World</description>
    <generator>Hugo -- 0.140.2</generator>
    <language>zh-TW</language>
    <lastBuildDate>Mon, 13 Jan 2025 15:00:00 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Hirarchical bayesian modeling</title>
      <link>http://localhost:1313/posts/%E8%B2%9D%E6%B0%8F%E5%88%86%E5%B1%A4%E5%BB%BA%E6%A8%A1/</link>
      <pubDate>Mon, 13 Jan 2025 15:00:00 +0800</pubDate>
      <guid>http://localhost:1313/posts/%E8%B2%9D%E6%B0%8F%E5%88%86%E5%B1%A4%E5%BB%BA%E6%A8%A1/</guid>
      <description>&lt;p&gt;&lt;strong&gt;這是給自己的一份學習紀錄，以免日子久了忘記這是甚麼理論XD&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Bayesian hierarchical modeling，譯為「貝氏分層建模」&lt;br&gt;
針對多個層級分析的一套統計方法&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;「Hierarchical modeling is used with information is available on &lt;strong&gt;several different levels&lt;/strong&gt; of observational &lt;strong&gt;units&lt;/strong&gt;」&lt;br&gt;
可以對多個不同層級的觀測單位的資訊進行分析，例如：&lt;br&gt;
&amp;ndash; 每個國家的每日感染病例的時間概況，單位是國家&lt;br&gt;
&amp;ndash; 多個油井產量的遞減曲線分析（油氣產量），單位是油藏區的油井&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;　&lt;strong&gt;引自維基百科&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;公式理論&#34;&gt;公式理論&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Bayes&amp;rsquo; theorem:&lt;br&gt;
the updated probability statements about $\theta_j$, given the occurence of event $y$,&lt;br&gt;
using the basic property of conditional probability, the posterior distribution will yield:
$$P(\theta \mid y) = \frac{P(\theta, y)}{P(y)} = \frac{P(y \mid \theta)P(\theta)}{P(y)}$$
so, we can say that:
$$P(\theta \mid y) \propto P(y \mid \theta)P(\theta)$$&lt;/li&gt;
&lt;li&gt;Hierarchical models:&lt;br&gt;
Bayesian hierarchical modeling makes use of two important concepts in deriving the posterior distribution namely:&lt;br&gt;
(1) &lt;strong&gt;Hyperparameters&lt;/strong&gt;: parameters of prior distribution&lt;br&gt;
　 先驗分配的參數（超參數／超母數）&lt;br&gt;
(2) &lt;strong&gt;Hyperdisrtibution&lt;/strong&gt;: distribution of hyperparameters&lt;br&gt;
　 超參數的分配&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;例如：我們需要建模學校的學生測驗成績&lt;/p&gt;</description>
    </item>
    <item>
      <title>Expectation maximization algorithm</title>
      <link>http://localhost:1313/posts/em%E6%BC%94%E7%AE%97%E6%B3%95/</link>
      <pubDate>Sun, 12 Jan 2025 11:00:00 +0800</pubDate>
      <guid>http://localhost:1313/posts/em%E6%BC%94%E7%AE%97%E6%B3%95/</guid>
      <description>&lt;p&gt;&lt;strong&gt;這是給自己的一份學習紀錄，以免日子久了忘記這是甚麼理論XD&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Expectation-maximization algorithm&lt;br&gt;
又翻譯為「最大期望值演算法」&lt;/li&gt;
&lt;li&gt;經過兩個步驟交替進行計算：&lt;br&gt;
第一步是計算期望值（E）：利用對隱藏變量的現有估計值，計算其最大概似估計值&lt;br&gt;
第二步是最大化（M）：最大化在E步上求得的最大概似值來計算參數的值
M步上找到的參數估計值被用於下一個E步計算中，這個過程不斷交替進行&lt;br&gt;
&lt;strong&gt;引自維基百科&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>cocktail webcrawler</title>
      <link>http://localhost:1313/posts/%E9%85%92%E8%AD%9C%E7%88%AC%E8%9F%B2%E6%95%99%E5%AD%B8/</link>
      <pubDate>Fri, 10 Jan 2025 13:30:00 +0800</pubDate>
      <guid>http://localhost:1313/posts/%E9%85%92%E8%AD%9C%E7%88%AC%E8%9F%B2%E6%95%99%E5%AD%B8/</guid>
      <description>&lt;p&gt;&lt;strong&gt;這是給我自己的一份教學，以免日子久了忘記怎麼爬蟲，同時也是一篇學習紀錄&lt;/strong&gt;&lt;br&gt;
&lt;strong&gt;擁有一個可以寫code的環境，網路上很多安裝環境的教學&lt;/strong&gt;&lt;br&gt;
&lt;strong&gt;我是用anoconda的vs code寫code的&lt;/strong&gt;&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;import requests as req
# 向客戶端要求網址  
from bs4 import BeautifulSoup as B
# 索取網址內容  
import pandas as pd
# 最後將結果輸出為CSV檔
import time
# 避免爬蟲時被抓到是爬蟲，所以移用這個延長每次爬蟲時間，假裝自己是人類
import random
# 延遲隨機時間用的
builder_url = &amp;#39;https://www.theeducatedbarfly.com/cocktail-builder/&amp;#39;
# 我是用 **cocktail builder** 這個網站來爬蟲我要的酒單  
header = {&amp;#39;User-Agent&amp;#39;: &amp;#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36&amp;#39;}
# 起初在爬的時候有發現跑不出資料，所以新增header來假裝我是人類，網路上也有很多如何在瀏覽器找header的教學
resp = req.get(builder_url, headers=header)
# 建立抓取url的回應變數
cocktail_name_list = []
# 建立空清單，將抓取到的資料先放進來，以便最後做成dataframe
if resp.status_code == 200:
# 確定你的url是可以連線的
    soup = B(resp.text, &amp;#39;html.parser&amp;#39;)
    # 建立爬蟲的頭頭，後面的html.parser是每次建立都要有，好像是用來解析html的功能
    for cocktail_name in soup.find_all(&amp;#39;div&amp;#39;, class_=&amp;#34;wpupg-item-title wpupg-block-text-bold&amp;#34;):
    # 打開網頁按下F2，按下ctrl+shift+c進入選取網頁元素模式，點選任一調酒，會指引到該調酒的block
    # 你會發現所有的調酒名稱都在&amp;#39;div&amp;#39;, class_=&amp;#34;wpupg-item-title wpupg-block-text-bold&amp;#34;這個標籤底下，所以我們利用find_all遍歷該標籤
        name = cocktail_name.text.strip()
        # 調酒名稱都在&amp;#39;div&amp;#39;, class_=&amp;#34;wpupg-item-title wpupg-block-text-bold&amp;#34;的標籤的text內容中，strip()是去掉text前後多餘的空格
        if name:
        # 確定該標籤有內容才抓，沒有就不抓
            cocktail_name_list.append(name)
            # 抓到修飾後的text並放入剛剛建立的list
    time.sleep(random.uniform(1,3))
    # 每次抓完一個就等待 1~3 秒

cocktail_name_df = pd.DataFrame(cocktail_name_list, columns=[&amp;#39;Name&amp;#39;])
# 將抓完後的清list建立成一個Dataframe，以Name當作該欄位的名稱

cocktail_data = []
# 這是最後的調酒名稱+該調酒的材料的空清單

for name in cocktail_name_df[&amp;#39;Name&amp;#39;]:
    urls = f&amp;#39;https://www.theeducatedbarfly.com/{name.replace(&amp;#34; &amp;#34;, &amp;#34;-&amp;#34;).lower()}/&amp;#39;
    # 建立每個調酒的url，點進去隨便一個調酒，你會發現網址是https://www.theeducatedbarfly.com/xxx-xxx/
    # xxx是該調酒的名稱，只是我們剛剛的調酒名稱list有大寫而且中間是空格不是-，所以用replace將空格替換成-，且轉為小寫
    resp = req.get(urls, headers=header)
    if resp.status_code == 200:
        soup = B(resp.text, &amp;#39;html.parser&amp;#39;)
        # 查找所有具有指定 class 的 &amp;lt;span&amp;gt; 元素
        ingredients = soup.find_all(&amp;#39;span&amp;#39;, class_=&amp;#39;wprm-recipe-ingredient-name&amp;#39;)
        ingredient_name_list = []
        for ingredient in ingredients:
        # 提取&amp;lt;a&amp;gt;標籤的文字內容
            ingredient_name = ingredient.find(&amp;#39;a&amp;#39;)
            if ingredient_name:  
            # 確保&amp;lt;a&amp;gt;存在
                ingredient_name_list.append(ingredient_name.text.strip())

        cocktail_data.append({&amp;#39;Cocktail Name&amp;#39;: name, &amp;#39;Ingredients&amp;#39;: &amp;#34;, &amp;#34;.join(ingredient_name_list)})
        # 最後就是將剛剛抓到的Name跟這個Inredients清單中每個素材加入剛剛建立的加入剛剛建立的cocktail_data清單中
    time.sleep(random.uniform(1,3))

cocktail_df = pd.DataFrame(cocktail_data)
# 最後的最後將list轉為Dataframe並用pd.to_csv輸出成csv檔，結束這回合
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;以上是我提醒自己的爬蟲教學&lt;/strong&gt;&lt;br&gt;
&lt;strong&gt;有任何疑問歡迎提出&lt;/strong&gt;&lt;br&gt;
&lt;del&gt;雖然我還沒有建立留言板就是了&lt;/del&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>My Learning Record</title>
      <link>http://localhost:1313/posts/my-learning-record/</link>
      <pubDate>Thu, 09 Jan 2025 15:30:00 +0800</pubDate>
      <guid>http://localhost:1313/posts/my-learning-record/</guid>
      <description></description>
    </item>
  </channel>
</rss>
