<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Dimensionality Reduction on Yang&#39;s World</title>
    <link>http://localhost:1313/tags/dimensionality-reduction/</link>
    <description>Recent content in Dimensionality Reduction on Yang&#39;s World</description>
    <generator>Hugo -- 0.140.2</generator>
    <language>zh-TW</language>
    <lastBuildDate>Fri, 21 Mar 2025 16:40:00 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/dimensionality-reduction/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Support Vector Machine Learning</title>
      <link>http://localhost:1313/posts/suportvectormachine/</link>
      <pubDate>Fri, 21 Mar 2025 16:40:00 +0800</pubDate>
      <guid>http://localhost:1313/posts/suportvectormachine/</guid>
      <description>&lt;h4 id=&#34;é€™æ˜¯çµ¦è‡ªå·±çš„ä¸€ä»½å­¸ç¿’ç´€éŒ„ä»¥å…æ—¥å­ä¹…äº†å¿˜è¨˜é€™æ˜¯ç”šéº¼ç†è«–xd&#34;&gt;é€™æ˜¯çµ¦è‡ªå·±çš„ä¸€ä»½å­¸ç¿’ç´€éŒ„ï¼Œä»¥å…æ—¥å­ä¹…äº†å¿˜è¨˜é€™æ˜¯ç”šéº¼ç†è«–XD&lt;/h4&gt;
&lt;h3 id=&#34;-support-vector-machine&#34;&gt;ğŸª¡ Support Vector Machine&lt;/h3&gt;</description>
    </item>
    <item>
      <title>Principal Component Analysis(PCA) Learning</title>
      <link>http://localhost:1313/posts/pca/</link>
      <pubDate>Tue, 04 Feb 2025 13:20:00 +0800</pubDate>
      <guid>http://localhost:1313/posts/pca/</guid>
      <description>&lt;h4 id=&#34;é€™æ˜¯çµ¦è‡ªå·±çš„ä¸€ä»½å­¸ç¿’ç´€éŒ„ä»¥å…æ—¥å­ä¹…äº†å¿˜è¨˜é€™æ˜¯ç”šéº¼ç†è«–xd&#34;&gt;é€™æ˜¯çµ¦è‡ªå·±çš„ä¸€ä»½å­¸ç¿’ç´€éŒ„ï¼Œä»¥å…æ—¥å­ä¹…äº†å¿˜è¨˜é€™æ˜¯ç”šéº¼ç†è«–XD&lt;/h4&gt;
&lt;h4 id=&#34;é€™ç¯‡æ–‡ç« åˆ©ç”¨-chat-gpt-ç¿»è­¯æˆè‹±æ–‡é‚Šå”¸é‚Šæ‰“ç´”æ‰‹æ‰“ç„¡è¤‡è£½è²¼ä¸Šé †ä¾¿ç·´è‹±æ–‡-xd&#34;&gt;é€™ç¯‡æ–‡ç« åˆ©ç”¨ Chat Gpt ç¿»è­¯æˆè‹±æ–‡ï¼Œé‚Šå”¸é‚Šæ‰“ï¼ˆç´”æ‰‹æ‰“ï¼Œç„¡è¤‡è£½è²¼ä¸Šï¼‰ï¼Œé †ä¾¿ç·´è‹±æ–‡ XD&lt;/h4&gt;
&lt;p&gt;We can assume that the data comes from a sample with a normal distribution, in this context, the eigenvalues asyptotically
follow a normal distribution. Therefore, we can estimate the 95% confidence interval for each eigenvalue using the following formula:
$$
\left[
\lambda_\alpha \left(
1 - 1.96 \sqrt{\frac{2}{n-1}}
\right); \lambda_\alpha \left(1 + 1.96 \sqrt{\frac{2}{n-1}}
\right)
\right]
$$
where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\lambda_\alpha$ represents the $\alpha$-th eigenvalue&lt;/li&gt;
&lt;li&gt;$n$ denotes the sample size.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By caculating the 95%
confidence intervals of the eigenvalue, we can assess their stability and determine the appropriate number of pricipal component axes to retain.
This approach aids in deciding how many principal components to keep in PCA to reduce data dimensionality while preserving as much of the original
information as possible.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
