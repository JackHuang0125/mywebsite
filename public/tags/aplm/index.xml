<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>APLM on Yang&#39;s World</title>
    <link>http://localhost:1313/tags/aplm/</link>
    <description>Recent content in APLM on Yang&#39;s World</description>
    <generator>Hugo -- 0.140.2</generator>
    <language>zh-TW</language>
    <lastBuildDate>Fri, 04 Oct 2024 16:02:00 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/aplm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Estimator in multivariable linear model</title>
      <link>http://localhost:1313/posts/aplm_hw1/</link>
      <pubDate>Fri, 04 Oct 2024 16:02:00 +0800</pubDate>
      <guid>http://localhost:1313/posts/aplm_hw1/</guid>
      <description>&lt;p&gt;&lt;strong&gt;這是給自己的一份學習紀錄，以免日子久了忘記這是甚麼理論XD&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Expectation-maximization algorithm&lt;br&gt;
又翻譯為「最大期望值演算法」&lt;/li&gt;
&lt;li&gt;經過兩個步驟交替進行計算：&lt;br&gt;
第一步是計算期望值（E）：利用對隱藏變量的現有估計值，計算其最大概似估計值&lt;br&gt;
第二步是最大化（M）：最大化在E步上求得的最大概似值來計算參數的值
M步上找到的參數估計值被用於下一個E步計算中，這個過程不斷交替進行&lt;br&gt;
&lt;strong&gt;引自維基百科&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
  </channel>
</rss>
